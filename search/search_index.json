{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PyTorch This contains PyTorch basic demo notebooks and scripts Paper PyTorch: An Imperative Style, High-Performance Deep Learning Library Content Topic SubTopic Section: 1 PyTorch Introduction Introduction to PyTorch PyTorch installation and setup Section: 2 PyTorch Tensors and Operations What is tensor? & Type Conversions Mathematical Operations Indexing, Slicing, Concatenation, Reshaping Ops Section: 3 AutoGrad Derivatives, Partial derivative, & Successive Differentiation Section: 4 First Neural Network Simple ANN Implementation","title":"Home"},{"location":"#pytorch","text":"This contains PyTorch basic demo notebooks and scripts","title":"PyTorch"},{"location":"#paper","text":"PyTorch: An Imperative Style, High-Performance Deep Learning Library","title":"Paper"},{"location":"#content","text":"Topic SubTopic Section: 1 PyTorch Introduction Introduction to PyTorch PyTorch installation and setup Section: 2 PyTorch Tensors and Operations What is tensor? & Type Conversions Mathematical Operations Indexing, Slicing, Concatenation, Reshaping Ops Section: 3 AutoGrad Derivatives, Partial derivative, & Successive Differentiation Section: 4 First Neural Network Simple ANN Implementation","title":"Content"},{"location":"Section_001_PyTorch_Introduction/","text":"Section: 1 PyTorch Introduction Introduction to PyTorch PyTorch official docs - pytorch.org PyTorch installation and setup PyTorch installation reference - Click here Notebook insallation command - pip install notebook Demo Notebooks - PyTorch installation and setup first demo - nbviewer","title":"Section 1 PyTorch Introduction"},{"location":"Section_001_PyTorch_Introduction/#section-1-pytorch-introduction","text":"","title":"Section: 1 PyTorch Introduction"},{"location":"Section_001_PyTorch_Introduction/#introduction-to-pytorch","text":"PyTorch official docs - pytorch.org","title":"Introduction to PyTorch"},{"location":"Section_001_PyTorch_Introduction/#pytorch-installation-and-setup","text":"PyTorch installation reference - Click here Notebook insallation command - pip install notebook","title":"PyTorch installation and setup"},{"location":"Section_001_PyTorch_Introduction/#demo-notebooks-","text":"PyTorch installation and setup first demo - nbviewer","title":"Demo Notebooks -"},{"location":"Section_002_PyTorch_Tensors_and_Operations/","text":"Section: 2 PyTorch Tensors and Operations What is tensor? A kind of data structure => multidimensional arrays or matrices With tensors you enocode all your parameters. Type Conversions Conversions from one datatype to another. Conversions from torch tensors to numpy arrays and vice versa. Demo Notebooks - What is tensor? & Type Conversions- nbviewer Mathematical Operations - nbviewer Indexing, Slicing, Concatenation, Reshaping Ops - nbviewer","title":"Section 2 PyTorch Tensors and Operations"},{"location":"Section_002_PyTorch_Tensors_and_Operations/#section-2-pytorch-tensors-and-operations","text":"","title":"Section: 2 PyTorch Tensors and Operations"},{"location":"Section_002_PyTorch_Tensors_and_Operations/#what-is-tensor","text":"A kind of data structure => multidimensional arrays or matrices With tensors you enocode all your parameters.","title":"What is tensor?"},{"location":"Section_002_PyTorch_Tensors_and_Operations/#type-conversions","text":"Conversions from one datatype to another. Conversions from torch tensors to numpy arrays and vice versa.","title":"Type Conversions"},{"location":"Section_002_PyTorch_Tensors_and_Operations/#demo-notebooks-","text":"What is tensor? & Type Conversions- nbviewer Mathematical Operations - nbviewer Indexing, Slicing, Concatenation, Reshaping Ops - nbviewer","title":"Demo Notebooks -"},{"location":"Section_003_AutoGrad/","text":"Section: 3 AutoGrad PyTorch has a capability of automatic gradient calculation ! Why we require AutoGrad ? When we do backpropragation we need to calculate gradient of loss function w.r.t weight If we do gradient calculation with hands it will take time and it won't be dynamic as then we would have to write each derivative manually. To resolve this issue PyTorch has a capability to calculate derivative of function automatically which is also known as AutoGrad. Info A simplified model of a PyTorch tensor is as an object containing the following properties: data \u2014 a self-reference. required_grad \u2014 whether or not this tensor is/should be connected to the computational graph. grad \u2014 if required_grad is true, this prop will be a sub-tensor that collects the gradients against this tensor accumulated during backwardpropagation. grad_fn \u2014 This is a reference to the most recent operation which generated this tensor. PyTorch performs automatic differentiation by looking through the grad_fn list. is_leaf \u2014 Whether or not this is a leaf node. Demo Notebooks - Derivatives, Partial derivative, & Successive Differentiation - nbviewer","title":"Section 3 AutoGrad"},{"location":"Section_003_AutoGrad/#section-3-autograd","text":"PyTorch has a capability of automatic gradient calculation !","title":"Section: 3 AutoGrad"},{"location":"Section_003_AutoGrad/#why-we-require-autograd","text":"When we do backpropragation we need to calculate gradient of loss function w.r.t weight If we do gradient calculation with hands it will take time and it won't be dynamic as then we would have to write each derivative manually. To resolve this issue PyTorch has a capability to calculate derivative of function automatically which is also known as AutoGrad. Info A simplified model of a PyTorch tensor is as an object containing the following properties: data \u2014 a self-reference. required_grad \u2014 whether or not this tensor is/should be connected to the computational graph. grad \u2014 if required_grad is true, this prop will be a sub-tensor that collects the gradients against this tensor accumulated during backwardpropagation. grad_fn \u2014 This is a reference to the most recent operation which generated this tensor. PyTorch performs automatic differentiation by looking through the grad_fn list. is_leaf \u2014 Whether or not this is a leaf node.","title":"Why we require AutoGrad ?"},{"location":"Section_003_AutoGrad/#demo-notebooks-","text":"Derivatives, Partial derivative, & Successive Differentiation - nbviewer","title":"Demo Notebooks -"},{"location":"Section_004_PyTorch_First_NN/","text":"Section 4: First Neural Network Demo Notebooks - Simple ANN Implementation - nbviewer","title":"Section 4 First Neural Network"},{"location":"Section_004_PyTorch_First_NN/#section-4-first-neural-network","text":"","title":"Section 4: First Neural Network"},{"location":"Section_004_PyTorch_First_NN/#demo-notebooks-","text":"Simple ANN Implementation - nbviewer","title":"Demo Notebooks -"},{"location":"references/","text":"References","title":"References"},{"location":"references/#references","text":"","title":"References"}]}